{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJni_Fa-JSXj"
   },
   "source": [
    "# Run this to load libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77744,
     "status": "ok",
     "timestamp": 1602101578548,
     "user": {
      "displayName": "Louis McCallum",
      "photoUrl": "",
      "userId": "16483688816273934191"
     },
     "user_tz": -60
    },
    "id": "kBKGosNv2Gti",
    "outputId": "bdddafb4-9ceb-4ae8-b523-8e13b08c5abc"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n",
    "!pip install -qU ddsp[data_preparation]\n",
    "\n",
    "# Initialize global path for using google drive. \n",
    "DRIVE_DIR = ''\n",
    "import os\n",
    "import ddsp\n",
    "import ddsp.training\n",
    "import gin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wavutils\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import librosa\n",
    "from ddsp.colab.colab_utils import play, specplot\n",
    "!git clone https://github.com/Louismac/network-bending/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vXbMKLuJtTa"
   },
   "source": [
    "# Define custom methods (just run the cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2370,
     "status": "ok",
     "timestamp": 1602105763095,
     "user": {
      "displayName": "Louis McCallum",
      "photoUrl": "",
      "userId": "16483688816273934191"
     },
     "user_tz": -60
    },
    "id": "BnVH2YI23Pdn"
   },
   "outputs": [],
   "source": [
    "class UnitProvider():\n",
    "  def __init__(self):\n",
    "    self.unit_list = []\n",
    "    self.units = 1;\n",
    "\n",
    "  def get_units(self, s):\n",
    "    if len(self.unit_list) == 0:\n",
    "        self.unit_list = np.arange(s)\n",
    "        np.random.shuffle(self.unit_list)\n",
    "        self.unit_list = self.unit_list[:int(s * self.units)]\n",
    "    #print(len(self.unit_list))\n",
    "    return self.unit_list\n",
    "\n",
    "class BendingParam():\n",
    "    def __init__(self):\n",
    "        self.t = 0\n",
    "        #number of vals in block\n",
    "        self.res = 1000\n",
    "        self.unit_list = []\n",
    "        self.lfo = False\n",
    "        self.ramp = False\n",
    "        self.scalar = 0\n",
    "        self.min = 0\n",
    "        self.max = 1\n",
    "        self.freq = 1\n",
    "        self.len = 1\n",
    "    \n",
    "    #return 1 block of params\n",
    "    def get_values(self):\n",
    "        vals = []\n",
    "        if self.lfo:\n",
    "          r = (self.max - self.min) / 2\n",
    "          vals = np.array([self.step_lfo() for i in range(self.res)])\n",
    "          vals = vals + (1 + self.min)\n",
    "          vals = vals * r\n",
    "        elif self.ramp:\n",
    "          vals = np.linspace(self.min, self.max, self.len * self.res)[self.t:self.t+self.res]\n",
    "          self.t = self.t + self.res\n",
    "        else:\n",
    "          vals = np.ones(self.res) * self.scalar\n",
    "        return vals\n",
    " \n",
    "    def step_lfo(self):\n",
    "        increment = (self.freq / self.res) * (np.pi * 2)\n",
    "        val = np.sin(self.t)\n",
    "        self.t = self.t + increment\n",
    "        return val\n",
    "        \n",
    "class BendingTransforms():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.t = 0;\n",
    "        self.res = 1000;\n",
    "        \n",
    "    def ablate(self, src, units):\n",
    "        src = src.numpy()\n",
    "        src = src.reshape((src.shape[1], src.shape[2]))\n",
    "        M, N = src.shape\n",
    "        units = units.get_units(N)\n",
    "        src[:,units] = 0\n",
    "        return src.reshape((1, M, N))\n",
    "    \n",
    "    def invert(self, src, units):\n",
    "        src = src.numpy()\n",
    "        src = src.reshape((src.shape[1], src.shape[2]))\n",
    "        M, N = src.shape\n",
    "        units = units.get_units(N)\n",
    "        src[:,units] = 1 - src[:,units]\n",
    "        return src.reshape((1, M, N))\n",
    "    \n",
    "    def threshold(self, src, thresh, units):\n",
    "        thresh = thresh.get_values()\n",
    "        #apply in axis 1 (time)\n",
    "        thresh = thresh.reshape((thresh.shape[0], 1))\n",
    "        src = src.numpy()\n",
    "        one, M, N = src.shape\n",
    "        src = src.reshape((M, N))\n",
    "        units = units.get_units(N)\n",
    "        #print(src[src < t], t, src)\n",
    "        src[:,units][src[:,units] < thresh] = 0\n",
    "        src[:,units][src[:,units] >= thresh] = 1\n",
    "        return src.reshape((1, M, N))\n",
    "                    \n",
    "    def step_osc(self, f = 1.0):\n",
    "        increment = (f / self.res) * (np.pi * 2)\n",
    "        self.t = self.t + increment\n",
    "        return np.sin(self.t)\n",
    "    \n",
    "    def oscillate(self, src, freq, depth, units):\n",
    "        src = src.numpy()\n",
    "        src = src.reshape((src.shape[1], src.shape[2]))\n",
    "        M, N = src.shape\n",
    "        f = freq.get_values()\n",
    "        d = depth.get_values()\n",
    "        b = np.array([self.step_osc(f[i]) for i in range(0,self.res)]) * d\n",
    "        #apply in axis 1 (time)\n",
    "        b = b.reshape(b.shape[0], 1)\n",
    "        units = units.get_units(N)\n",
    "        src[:,units] = src[:,units] + b\n",
    "        return src.reshape((1, M, N))\n",
    "\n",
    "    def reflect(self, src, r, units):\n",
    "        alpha = r\n",
    "        a = np.array([[np.cos(2*alpha), np.sin(2*alpha)],\n",
    "                      [np.sin(2*alpha), -np.cos(2*alpha)]])\n",
    "        return self.linear_transformation(src, a)\n",
    "    \n",
    "    def rotate(self, src, radians, units):\n",
    "        alpha = radians\n",
    "        a = np.array([[np.cos(alpha), -np.sin(alpha)],\n",
    "                      [np.sin(alpha), np.cos(alpha)]])\n",
    "        return self.linear_transformation(src, a)\n",
    "    \n",
    "    def linear_transformation(self, src, a):\n",
    "        src = src.numpy()\n",
    "        src = src.reshape((src.shape[1], src.shape[2]))\n",
    "        M, N = src.shape\n",
    "        points = np.mgrid[0:N, 0:M].reshape((2, M*N))\n",
    "        new_points = np.linalg.inv(a).dot(points).round().astype(int)\n",
    "        x, y = new_points.reshape((2, M, N), order='F')\n",
    "        indices = x + N*y\n",
    "        wrap = np.take(src, indices, mode='wrap').reshape((1, M, N))\n",
    "        t = tf.constant(wrap)\n",
    "        return t\n",
    "\n",
    "class BendingDecoder(ddsp.training.decoders.RnnFcDecoder):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(\"bending init called\")\n",
    "\n",
    "    def init_params(self):\n",
    "        print(\"init_params\")\n",
    "        self.t = {}\n",
    "        self.t[\"FC1\"] = []\n",
    "        self.t[\"FC2\"] = []\n",
    "        self.t[\"GRU\"] = []\n",
    "        \n",
    "    def add_transform(self, layer, f, a):\n",
    "        self.t[layer].append(tf.keras.layers.Lambda(f, arguments = a))\n",
    "        \n",
    "    def decode(self, conditioning):\n",
    "        # Initial processing.\n",
    "        inputs = [conditioning[k] for k in self.input_keys]\n",
    "        #print(conditioning[\"f0_hz\"].shape)\n",
    "        inputs = [stack(x) for stack, x in zip(self.input_stacks, inputs)]\n",
    "        # Run an RNN over the latents.\n",
    "        x = tf.concat(inputs, axis=-1)\n",
    "        #print(x.shape)\n",
    "        for f in self.t[\"FC1\"]:\n",
    "            x = f(x)\n",
    "        x = self.rnn(x)\n",
    "        #print(x.shape)\n",
    "        for f in self.t[\"GRU\"]:\n",
    "            x = f(x)\n",
    "        x = tf.concat(inputs + [x], axis=-1)\n",
    "        #print(x.shape)\n",
    "        # Final processing.\n",
    "        x = self.out_stack(x)\n",
    "        #print(x.shape)\n",
    "        for f in self.t[\"FC2\"]:\n",
    "            x = f(x)\n",
    "        return self.dense_out(x)\n",
    "\n",
    "class Generator():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = [\"FC1\", \"GRU\", \"FC2\"]\n",
    "        self.transforms = {}\n",
    "        self.buf_length = 16000\n",
    "        for l in self.layers:\n",
    "            self.transforms[l] = BendingTransforms()\n",
    "    \n",
    "    # setup tensorflow, the feature extractor and the model\n",
    "    def setup_resynthesis(self, model_dir):\n",
    "        #self.setup_tensorflow()\n",
    "        ddsp.spectral_ops.reset_crepe()\n",
    "        self.setup_model(model_dir)\n",
    "        print(\"setup_resynthesis::resynthesis ready probably\")\n",
    "        self.model.decoder.__class__ = BendingDecoder\n",
    "        self.model.decoder.init_params()\n",
    "    \n",
    "    def setup_tensorflow(self):\n",
    "        config = tf.compat.v1.ConfigProto()\n",
    "        session = tf.compat.v1.Session(config=config)\n",
    "        tf.compat.v1.keras.backend.set_session(session)\n",
    "        print(\"setup_tensorflow\")\n",
    "        \n",
    "    def setup_model(self, model_dir):\n",
    "        gin_file = os.path.join(model_dir, 'operative_config-0.gin')\n",
    "\n",
    "        if os.path.isfile(gin_file) != True:\n",
    "            print(\"setup_model::Gin file not found: \", gin_file)\n",
    "            return \n",
    "\n",
    "         # Parse gin config,\n",
    "        with gin.unlock_config():\n",
    "            gin.parse_config_file(gin_file, skip_unknown=True)\n",
    "\n",
    "        # Assumes only one checkpoint in the folder, 'ckpt-[iter]`.\n",
    "        ckpt_files = [f for f in tf.io.gfile.listdir(model_dir) if 'ckpt' in f]\n",
    "        ckpt_name = ckpt_files[0].split('.')[0]\n",
    "        ckpt = os.path.join(model_dir, ckpt_name)\n",
    "\n",
    "        # Ensure dimensions and sampling rates are equal\n",
    "        time_steps_train = gin.query_parameter('DefaultPreprocessor.time_steps')\n",
    "        n_samples_train = gin.query_parameter('Additive.n_samples')\n",
    "        hop_size = int(n_samples_train / time_steps_train)\n",
    "\n",
    "        time_steps = int(self.buf_length / hop_size)\n",
    "        required_input_samples = time_steps * hop_size\n",
    "        print(\"time steps\", time_steps, time_steps_train)\n",
    "        print(\"input_samples\", required_input_samples, n_samples_train)\n",
    "\n",
    "        gin_params = [\n",
    "            'RnnFcDecoder.input_keys = (\"f0_scaled\", \"ld_scaled\", \"z\")',\n",
    "            'Additive.n_samples = {}'.format(required_input_samples),\n",
    "            'FilteredNoise.n_samples = {}'.format(required_input_samples),\n",
    "            'DefaultPreprocessor.time_steps = {}'.format(time_steps),\n",
    "        ]\n",
    "\n",
    "        # with gin.unlock_config():\n",
    "        #     gin.parse_config(gin_params)\n",
    "\n",
    "        # Set up the model just to predict audio given new conditioning\n",
    "        self.model = ddsp.training.models.Autoencoder()\n",
    "        self.model.restore(ckpt) \n",
    "        # gin_file = os.path.join(model_dir, 'operative_config-0.gin')\n",
    "        # gin.parse_config_file(gin_file)\n",
    "        # self.model = ddsp.training.models.Autoencoder()\n",
    "        # self.model.restore(model_dir)\n",
    "    \n",
    "    def resynth_batch(self, data_dir):\n",
    "        TRAIN_TFRECORD = data_dir + '/train.tfrecord'\n",
    "        TRAIN_TFRECORD_FILEPATTERN = TRAIN_TFRECORD + '*'\n",
    "        data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
    "        dataset = data_provider.get_batch(batch_size=1, shuffle=False)\n",
    "\n",
    "        try:\n",
    "          batch = next(iter(dataset))\n",
    "        except OutOfRangeError:\n",
    "          raise ValueError(\n",
    "              'TFRecord contains no examples. Please try re-running the pipeline with '\n",
    "              'different audio file(s).')\n",
    "        print(batch[\"f0_hz\"].shape)\n",
    "        audio_gen = self.model(batch, training=False)\n",
    "        return audio_gen, batch['audio']\n",
    "\n",
    "    def get_audio_input_file(self, file_name):\n",
    "      signal, sr=librosa.load(file_name, sr=16000, mono = True,)\n",
    "      print(len(signal))\n",
    "      return np.array(signal), sr\n",
    "\n",
    "    def extract_audio_file_features(self, audio_signal, sr):        \n",
    "        start_time = time.time()\n",
    "        print('Extracting features (may take a while). Sig length ', len(audio_signal))\n",
    "        audio_features = ddsp.training.metrics.compute_audio_features(audio_signal, sample_rate=sr)\n",
    "        print('extract_input_fetures:: Audio features took %.1f seconds' % (time.time() - start_time))\n",
    "        audio_features['loudness_db'] = audio_features['loudness_db'].astype(np.float32)\n",
    "        return audio_features\n",
    "        \n",
    "    def load_features(self, file_name):\n",
    "      input_file = file_name\n",
    "      INPUT_AUDIO_FILE_PATH = os.path.join(AUDIO_DATA_DIR,input_file+\".wav\")\n",
    "      INPUT_DATA_FILE_PATH = os.path.join(AUDIO_DATA_DIR,input_file+\".csv\")\n",
    "      audio_sig, sr = self.get_audio_input_file(INPUT_AUDIO_FILE_PATH)\n",
    "      specplot(audio_sig)\n",
    "      play(audio_sig,sample_rate=sr)\n",
    "      if not os.path.exists(INPUT_DATA_FILE_PATH):\n",
    "        audio_features = self.extract_audio_file_features(audio_sig, sr)\n",
    "        stacked = np.stack((audio_features[\"f0_hz\"], audio_features[\"loudness_db\"],audio_features[\"f0_confidence\"]), axis=1)\n",
    "        df = pd.DataFrame(stacked,columns=[\"f0_hz\",\"loudness_db\",\"f0_confidence\"])\n",
    "        print('writing features to file', INPUT_DATA_FILE_PATH)\n",
    "        df.to_csv(INPUT_DATA_FILE_PATH)\n",
    "      else:\n",
    "        print(\"features already extracted, found csv\") \n",
    "\n",
    "    def load_file_features(self, name, start = 0.0, end = 1.0):\n",
    "        df = pd.read_csv(os.path.join(AUDIO_DATA_DIR,name + \".csv\"))\n",
    "        total = np.array(df[\"f0_hz\"]).shape[0]\n",
    "        start = int(total * start)\n",
    "        end = int(total * end)\n",
    "        print(\"loaded features from {s} to {e}\".format(s=start, e=end))\n",
    "        features = {}\n",
    "        features[\"f0_hz\"] = np.array(df[\"f0_hz\"])[start:end]\n",
    "        features[\"loudness_db\"] = np.array(df[\"loudness_db\"])[start:end]\n",
    "        features[\"f0_confidence\"] = np.array(df[\"f0_confidence\"])[start:end]\n",
    "        audio,sr = self.get_audio_input_file(os.path.join(AUDIO_DATA_DIR,name + \".wav\"))\n",
    "        total = len(audio)\n",
    "        start = int(total * start)\n",
    "        end = int(total * end)\n",
    "        features[\"audio\"] = audio[start:end]\n",
    "        features[\"sr\"] = sr\n",
    "        return features\n",
    "    \n",
    "    def write_file(self, output, config = None, normalise = False, sample_rate = 16000):\n",
    "        complete_output = np.zeros((2, len(output)))\n",
    "        complete_output[0] = complete_output[1] = output\n",
    "\n",
    "        print(\"main:: synthesis ends...\" + str(len(output)))\n",
    "\n",
    "        now = datetime.datetime.now()\n",
    "        output_root = now.strftime(\"%Y%m%d%H%M%S\")\n",
    "        output_audio_file = output_root + \".wav\"\n",
    "        output_json_file = output_root + \".json\"\n",
    "        boost_left = boost_right = 1\n",
    "        if normalise:\n",
    "          boost_left = self.get_normalise_scalar(complete_output[0])\n",
    "          boost_right = self.get_normalise_scalar(complete_output[1])\n",
    "        \n",
    "        if not config == None:\n",
    "          output_file = os.path.join(AUDIO_DATA_DIR, output_json_file);\n",
    "          print(\"writing config to json\", output_file)\n",
    "          with open(output_file, 'w') as outfile:\n",
    "              json.dump(config, outfile)\n",
    "\n",
    "        complete_output[0] = complete_output[0] * boost_left\n",
    "        complete_output[1] = complete_output[1] * boost_right\n",
    "\n",
    "        amplitude = np.iinfo(np.int16).max\n",
    "        complete_output = complete_output * amplitude\n",
    "        #now rotate it from [[ch1...], [ch2...] to [[c1, c2], [c1, c2] ..]\n",
    "        complete_output = np.rot90(complete_output, 3) # 3 as 1 is reversed\n",
    "        #complete_output = np.array([int((x + 1) * 32768) for x in complete_output])\n",
    "        output_path = os.path.join(AUDIO_DATA_DIR, output_audio_file);\n",
    "        wavutils.write(output_path, sample_rate, complete_output.astype(np.int16))\n",
    "\n",
    "        print(\"main:: wrote result to \", output_file)\n",
    "        \n",
    "    def get_normalise_scalar(self, buffer):\n",
    "        max = 0\n",
    "        for i in range(len(buffer)):\n",
    "            if np.abs(buffer[i]) > max:\n",
    "                max = np.abs(buffer[i])\n",
    "        scalar = 1/max\n",
    "        return scalar\n",
    "    \n",
    "    def get_output_signal(self, audio_features):\n",
    "        output = [self.get_block(i) for i in audio_features]\n",
    "        faded = []\n",
    "        output = np.array(output).flatten()\n",
    "        return output\n",
    "    \n",
    "    def get_block(self, ft):\n",
    "      print(\"getting next block\")\n",
    "      outputs = self.model(ft, training=False)\n",
    "      audio = self.model.get_audio_from_outputs(outputs)\n",
    "      return audio\n",
    "    \n",
    "    def get_audio_features(self, config, floor = True):\n",
    "        audio_features = self.load_file_features(\n",
    "          config[\"features\"][\"file_name\"], \n",
    "          config[\"features\"][\"start\"],\n",
    "          config[\"features\"][\"end\"]\n",
    "        )\n",
    "        self.buf_length = config[\"input_buf_length\"]\n",
    "        self.frames = config[\"frames\"]\n",
    "        db_boost = config[\"db_boost\"]\n",
    "        r = np.floor if floor else np.ceil\n",
    "        steps = r(len(audio_features[\"f0_hz\"]) / self.frames )\n",
    "        def get_dict(start, af):\n",
    "            d = {}\n",
    "            f_start = int(start * self.frames )\n",
    "            s_start = int(start * self.buf_length)\n",
    "            d[\"f0_hz\"] = af[\"f0_hz\"][f_start:f_start+self.frames]\n",
    "            d[\"loudness_db\"] = af[\"loudness_db\"][f_start:f_start+self.frames ] + db_boost\n",
    "            d[\"f0_confidence\"] = af[\"f0_confidence\"][f_start:f_start+self.frames]\n",
    "            delta = self.frames - len(d[\"f0_hz\"])\n",
    "            if delta > 0:\n",
    "               d[\"f0_hz\"] = np.append(d[\"f0_hz\"], np.zeros(delta))\n",
    "               d[\"f0_confidence\"] = np.append(d[\"f0_confidence\"], np.zeros(delta))\n",
    "               d[\"loudness_db\"] = np.append(d[\"loudness_db\"], np.zeros(delta))\n",
    "            d[\"audio\"] = [af[\"audio\"][s_start:s_start+self.buf_length]]\n",
    "            return d\n",
    "\n",
    "        split = [get_dict(i, audio_features) for i in np.arange(steps)]\n",
    "        return np.array(split), steps\n",
    "\n",
    "    def add_transforms(self, config, duration):\n",
    "      for l in self.layers:\n",
    "        #if transforms given for layer l\n",
    "        if l in config.keys():\n",
    "          c = config[l]\n",
    "          for f in c:\n",
    "            arg = {}\n",
    "            units = 1;\n",
    "            if \"units\" in f.keys():\n",
    "                units = f[\"units\"]\n",
    "            arg[\"units\"] = UnitProvider()\n",
    "            arg[\"units\"].units = units\n",
    "            if \"params\" in f.keys():\n",
    "              for p in f[\"params\"]:\n",
    "                  arg[p[\"name\"]] = BendingParam()\n",
    "                  arg[p[\"name\"]].res = self.frames \n",
    "                  arg[p[\"name\"]].len = int(np.ceil(duration))\n",
    "                  if \"args\" in p.keys():\n",
    "                      for k,v in p[\"args\"].items():\n",
    "                          setattr(arg[p[\"name\"]], k, v)\n",
    "            self.model.decoder.add_transform(l, getattr(self.transforms[l], f[\"function\"]), arg)\n",
    "\n",
    "    def generate(self, config):\n",
    "      self.setup_resynthesis(config[\"model_dir\"])\n",
    "      audio_features, duration = self.get_audio_features(config)\n",
    "      for l in self.layers:\n",
    "        self.transforms[l].res = self.frames;\n",
    "      self.add_transforms(config, duration)\n",
    "      output = self.get_output_signal(audio_features)\n",
    "      print(\"DONE\")\n",
    "      return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E80_1_hlJmar"
   },
   "source": [
    "# Specify Model and drive folder\n",
    "You'll need to specify the path to somewhere on your own drive, and have copied across a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1602101778612,
     "user": {
      "displayName": "Louis McCallum",
      "photoUrl": "",
      "userId": "16483688816273934191"
     },
     "user_tz": -60
    },
    "id": "VrMwGgLi3jZ8"
   },
   "outputs": [],
   "source": [
    "model_name = \"Whitney\"\n",
    "DRIVE_DIR = '/content/network-bending'\n",
    "if DRIVE_DIR:\n",
    "  MODEL_DIR = os.path.join(DRIVE_DIR, 'Models/' + model_name)\n",
    "  AUDIO_DATA_DIR = os.path.join(DRIVE_DIR, 'audio_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH1YxsnWJy5-"
   },
   "source": [
    "# Analyse audio, only does it first time, will save as .CSV\n",
    "Give the name of a .wav file in the AUDIO_DATA_DIR (\"audio_data\")\n",
    "\n",
    "Make sure GPU acceleration is on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "executionInfo": {
     "elapsed": 7691,
     "status": "ok",
     "timestamp": 1602105775501,
     "user": {
      "displayName": "Louis McCallum",
      "photoUrl": "",
      "userId": "16483688816273934191"
     },
     "user_tz": -60
    },
    "id": "mhr-8w8R3W9u",
    "outputId": "e53dfee0-1847-4949-cfe5-9ffd2225ef78"
   },
   "outputs": [],
   "source": [
    "g = Generator()\n",
    "input_file = \"monk-48\"\n",
    "g.load_features(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUBBd7L9KK2c"
   },
   "source": [
    "# Specify transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17128,
     "status": "ok",
     "timestamp": 1602107030589,
     "user": {
      "displayName": "Louis McCallum",
      "photoUrl": "",
      "userId": "16483688816273934191"
     },
     "user_tz": -60
    },
    "id": "dfkV0Z_s5VIa",
    "outputId": "856ac61a-582f-4959-edf6-2f6068b623c5"
   },
   "outputs": [],
   "source": [
    "##See Instructions (https://github.com/Louismac/network-bending/blob/main/README.md)\n",
    "config = {}\n",
    "config[\"model_dir\"] = MODEL_DIR\n",
    "#pick how much of input file to do (0->1)\n",
    "config[\"features\"] = {\"file_name\":input_file, \"start\":0.65, \"end\":0.85}\n",
    "#add boost to loudness feature of input\n",
    "config[\"db_boost\"] = 10\n",
    "#4 secs at 16000\n",
    "config[\"input_buf_length\"] = 4 * 16000\n",
    "config[\"frames\"] = 1000\n",
    "#transforms for first layer\n",
    "config[\"FC1\"] = [\n",
    " {\n",
    "    \"function\":\"oscillate\",\n",
    "    \"units\":0.7,\n",
    "    \"params\":[\n",
    "        {\"name\":\"depth\",\n",
    "         \"args\":{\n",
    "            \"lfo\":True,\n",
    "            \"freq\":1,\n",
    "            \"min\":0.1,\n",
    "            \"max\":0.4,\n",
    "            }\n",
    "        },\n",
    "        {\"name\":\"freq\",\n",
    "         \"args\":{\n",
    "            \"lfo\":True,\n",
    "            \"freq\":0.5,\n",
    "            \"min\":3,\n",
    "            \"max\":5,\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "]\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "audio_gen = g.generate(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXG1HQaYKWo6"
   },
   "source": [
    "# Audition output\n",
    "We zero pad the end so thats what the noise is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "executionInfo": {
     "elapsed": 1859,
     "status": "ok",
     "timestamp": 1602107033199,
     "user": {
      "displayName": "Louis McCallum",
      "photoUrl": "",
      "userId": "16483688816273934191"
     },
     "user_tz": -60
    },
    "id": "rUoQ_hR58QGm",
    "outputId": "fa9ed8c9-03db-4504-d6ca-e15ebf8a95a7"
   },
   "outputs": [],
   "source": [
    "\n",
    "specplot(audio_gen)\n",
    "play(audio_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4WpX4dCJQta"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNfyhjLS9H2K5620GFoeo7T",
   "collapsed_sections": [
    "NJni_Fa-JSXj"
   ],
   "name": "NetworkBending.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
